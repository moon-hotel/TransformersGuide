<p align="center">
    <br>
    <img src="./Images/transformers_logo_name.png" width="400"/>
    <br>
</p>
<h3 align="center">
<p>State-of-the-art Natural Language Processing for PyTorch and TensorFlow 2.0</p>
<h4 align = "center">
     <a href="https://huggingface.co/transformers/">原指导手册地址</a> &nbsp;&nbsp;&nbsp;&nbsp; <a href="https://github.com/huggingface/transformers">原项目Github地址 </a>  
  </h4>
</h3>
<h3 align = "center">Transformers指导手册中文翻译项目</h3> 

鉴于能力有限，翻译内容肯定存在一些错误，欢迎各位朋友不吝指教。同时，一个人的能力总是有限，欢迎有兴趣的朋友来和我们一起翻译！

# 特性

- 高性能：使用*Transformers*能够轻松地在NLU和NLG任务上取得很好的效果；
- 低门槛：使用*Transformers*能够轻松地实现各种NLU和NLG模型；

# 简单上手

- [*Transformers*介绍](000_Transformers.md)
  - [特性](000_Transformers.md/#特性)
  - [目录](000_Transformers.md/#目录)
- [快速指引](./001_QuickTutorial.md)
  - [通过管道来开始我们的第一个任务](./001_QuickTutorial.md/#1-通过管道来开始我们的第一个任务)
  - [预训练模型的内幕](./001_QuickTutorial.md/#2-预训练模型的内幕)
- [安装](002_Installation.md)
  - [通过`pip install`进行安装](002_Installation.md/#1-通过pip-install进行安装)
  - [通过源码进行安装](002_Installation.md/#2-通过源码进行安装)
  - [模型缓存路径](002_Installation.md/#3-模型缓存路径)
  - [在移动终端上使用*Transformers*](002_Installation.md/#4-在移动终端上使用transformers)
- [设计理念](003_Philosophy.md)
  - [主要概念](003_Philosophy.md/#主要概念)
- [术语介绍](./004_Glossary.md)
  - [术语总览](./004_Glossary.md/#1-术语总览)
  - [ 模型输入](./004_Glossary.md/#2-模型输入)
- [任务总结](./100_SummaryOfTasks.md)
  - [序列分类任务](./100_SummaryOfTasks.md/#1-序列分类任务)
  - [ 问题答案抽取](./100_SummaryOfTasks.md/#2-问题答案抽取)
  - [掩体语言模型](./100_SummaryOfTasks.md/#3-掩体语言模型)
  - [因果语言模型](./100_SummaryOfTasks.md/#4-因果语言模型)
  - [文本生成模型](./100_SummaryOfTasks.md/#5-文本生成模型)
  - [命名体识别](./100_SummaryOfTasks.md/#6-命名体识别)
  - [摘要生成](./100_SummaryOfTasks.md/#7-摘要生成)
  - [翻译](./100_SummaryOfTasks.md/#8-翻译)

